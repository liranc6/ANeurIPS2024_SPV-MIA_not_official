{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c3030bca",
      "metadata": {
        "id": "c3030bca"
      },
      "source": [
        "# Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7dce8f59",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dce8f59",
        "outputId": "cf55f94d-74d7-4610-ea50-0a6defe55e14"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(True, 'NVIDIA A40')"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check GPU availability\n",
        "import torch\n",
        "torch.cuda.is_available(), torch.cuda.get_device_name(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a1b0fe7e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1b0fe7e",
        "outputId": "f3a48a37-6864-4e50-e332-4a5423537820"
      },
      "outputs": [],
      "source": [
        "# Remove old clone\n",
        "# import os, shutil\n",
        "\n",
        "# repo_name = \"ANeurIPS2024_SPV-MIA\"\n",
        "# if os.path.basename(os.getcwd()) == repo_name:\n",
        "#     %cd ..\n",
        "# if os.path.exists(repo_name):\n",
        "#     print(f\"Removing existing {repo_name}...\")\n",
        "#     shutil.rmtree(repo_name)\n",
        "\n",
        "# Clone fork\n",
        "# !git clone https://github.com/maidesu/ANeurIPS2024_SPV-MIA.git\n",
        "# %cd ANeurIPS2024_SPV-MIA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "X2GeMmzFo6dp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2GeMmzFo6dp",
        "outputId": "eae52082-a711-47fb-d3d4-cee449a6b86c"
      },
      "outputs": [],
      "source": [
        "# !pip install -q -r requirements-colab.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a6c8bdc",
      "metadata": {
        "id": "0a6c8bdc"
      },
      "source": [
        "# Target Model Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "480bd020",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "480bd020",
        "outputId": "dd263dfa-af40-4749-cfe6-47de134f7231"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Script exists: True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/liranc6/miniconda3/envs/spv_attack311/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "/home/liranc6/miniconda3/envs/spv_attack311/lib/python3.11/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "full_path='/home/liranc6/W25/adversarial-attacks-on-deep-learning/project/ANeurIPS2024_SPV-MIA_not_official/project'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/liranc6/miniconda3/envs/spv_attack311/lib/python3.11/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/home/liranc6/miniconda3/envs/spv_attack311/lib/python3.11/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "/home/liranc6/miniconda3/envs/spv_attack311/lib/python3.11/site-packages/peft/tuners/lora/model.py:311: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 2359296 || all params: 126799104 || trainable%: 1.8606566809809635\n",
            "Folder './cache/wikitext/wikitext-2-raw-v1' already exists.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using pad_token, but it is not set yet.\n",
            "/home/liranc6/miniconda3/envs/spv_attack311/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:166: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
            "  warnings.warn(\n",
            "Map: 100%|██████████| 2000/2000 [00:00<00:00, 8572.24 examples/s]\n",
            "Map: 100%|██████████| 500/500 [00:00<00:00, 7987.20 examples/s]\n",
            "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='301' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 301/2000 00:30 < 02:54, 9.73 it/s, Epoch 0.30/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>4.230400</td>\n",
              "      <td>3.836797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>4.078800</td>\n",
              "      <td>3.765302</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  6/125 00:00 < 00:02, 47.03 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mllms_finetune\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m main_llms_finetune\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# Run the fine-tuning with the dictionary arguments\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m \u001b[43mmain_llms_finetune\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Launch fine-tuning test using gpt2 and small wikitext-2-raw-v1 slice\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# !accelerate launch ./ft_llms/llms_finetune.py \\\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# --output_dir ./ft_llms/gpt2/wikitext/target/ \\\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     46\u001b[39m \u001b[38;5;66;03m# --train_sta_idx=0 --train_end_idx=2000 --eval_sta_idx=0 --eval_end_idx=500 \\\u001b[39;00m\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# --dataset_config_name wikitext-2-raw-v1\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/W25/adversarial-attacks-on-deep-learning/project/ANeurIPS2024_SPV-MIA_not_official/ft_llms/llms_finetune.py:245\u001b[39m, in \u001b[36mmain_llms_finetune\u001b[39m\u001b[34m(args)\u001b[39m\n\u001b[32m    242\u001b[39m logger.info(training_args)\n\u001b[32m    244\u001b[39m \u001b[38;5;66;03m# train\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args.disable_peft:\n\u001b[32m    248\u001b[39m     model = model.merge_and_unload()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/spv_attack311/lib/python3.11/site-packages/transformers/trainer.py:1591\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   1589\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   1590\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1591\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1592\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1593\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1594\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1595\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1596\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/spv_attack311/lib/python3.11/site-packages/transformers/trainer.py:1984\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   1981\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.epoch = epoch + (step + \u001b[32m1\u001b[39m + steps_skipped) / steps_in_epoch\n\u001b[32m   1982\u001b[39m     \u001b[38;5;28mself\u001b[39m.control = \u001b[38;5;28mself\u001b[39m.callback_handler.on_step_end(args, \u001b[38;5;28mself\u001b[39m.state, \u001b[38;5;28mself\u001b[39m.control)\n\u001b[32m-> \u001b[39m\u001b[32m1984\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1985\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1986\u001b[39m     \u001b[38;5;28mself\u001b[39m.control = \u001b[38;5;28mself\u001b[39m.callback_handler.on_substep_end(args, \u001b[38;5;28mself\u001b[39m.state, \u001b[38;5;28mself\u001b[39m.control)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/spv_attack311/lib/python3.11/site-packages/transformers/trainer.py:2328\u001b[39m, in \u001b[36mTrainer._maybe_log_save_evaluate\u001b[39m\u001b[34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2326\u001b[39m         metrics.update(dataset_metrics)\n\u001b[32m   2327\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2328\u001b[39m     metrics = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2329\u001b[39m \u001b[38;5;28mself\u001b[39m._report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m.state.global_step, metrics)\n\u001b[32m   2331\u001b[39m \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/spv_attack311/lib/python3.11/site-packages/transformers/trainer.py:3066\u001b[39m, in \u001b[36mTrainer.evaluate\u001b[39m\u001b[34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[39m\n\u001b[32m   3063\u001b[39m start_time = time.time()\n\u001b[32m   3065\u001b[39m eval_loop = \u001b[38;5;28mself\u001b[39m.prediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.use_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.evaluation_loop\n\u001b[32m-> \u001b[39m\u001b[32m3066\u001b[39m output = \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3067\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3068\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEvaluation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3069\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[32m   3070\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[32m   3071\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   3072\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3073\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3074\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3076\u001b[39m total_batch_size = \u001b[38;5;28mself\u001b[39m.args.eval_batch_size * \u001b[38;5;28mself\u001b[39m.args.world_size\n\u001b[32m   3077\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_jit_compilation_time\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output.metrics:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/spv_attack311/lib/python3.11/site-packages/transformers/trainer.py:3245\u001b[39m, in \u001b[36mTrainer.evaluation_loop\u001b[39m\u001b[34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[39m\n\u001b[32m   3243\u001b[39m observed_num_examples = \u001b[32m0\u001b[39m\n\u001b[32m   3244\u001b[39m \u001b[38;5;66;03m# Main evaluation loop\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3245\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3246\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Update the observed num examples\u001b[39;49;00m\n\u001b[32m   3247\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobserved_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mfind_batch_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3248\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/spv_attack311/lib/python3.11/site-packages/accelerate/data_loader.py:393\u001b[39m, in \u001b[36mDataLoaderShard.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    390\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    391\u001b[39m     \u001b[38;5;66;03m# But we still move it to the device so it is done before `StopIteration` is reached\u001b[39;00m\n\u001b[32m    392\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m393\u001b[39m         current_batch = \u001b[43msend_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    394\u001b[39m     next_batch = \u001b[38;5;28mnext\u001b[39m(dataloader_iter)\n\u001b[32m    395\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m batch_index >= \u001b[38;5;28mself\u001b[39m.skip_batches:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/spv_attack311/lib/python3.11/site-packages/accelerate/utils/operations.py:160\u001b[39m, in \u001b[36msend_to_device\u001b[39m\u001b[34m(tensor, device, non_blocking, skip_keys)\u001b[39m\n\u001b[32m    157\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m skip_keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    158\u001b[39m         skip_keys = []\n\u001b[32m    159\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensor)(\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m         \u001b[43m{\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m            \u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mskip_keys\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msend_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m    164\u001b[39m     )\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(tensor, \u001b[33m\"\u001b[39m\u001b[33mto\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/spv_attack311/lib/python3.11/site-packages/accelerate/utils/operations.py:161\u001b[39m, in \u001b[36m<dictcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    157\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m skip_keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    158\u001b[39m         skip_keys = []\n\u001b[32m    159\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensor)(\n\u001b[32m    160\u001b[39m         {\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m             k: t \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m skip_keys \u001b[38;5;28;01melse\u001b[39;00m \u001b[43msend_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m k, t \u001b[38;5;129;01min\u001b[39;00m tensor.items()\n\u001b[32m    163\u001b[39m         }\n\u001b[32m    164\u001b[39m     )\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(tensor, \u001b[33m\"\u001b[39m\u001b[33mto\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/spv_attack311/lib/python3.11/site-packages/accelerate/utils/operations.py:167\u001b[39m, in \u001b[36msend_to_device\u001b[39m\u001b[34m(tensor, device, non_blocking, skip_keys)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(tensor, \u001b[33m\"\u001b[39m\u001b[33mto\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    168\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# .to() doesn't accept non_blocking as kwarg\u001b[39;00m\n\u001b[32m    169\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m tensor.to(device)\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# Get the path to llms_finetune.py\n",
        "finetune_script_path = \"/home/liranc6/W25/adversarial-attacks-on-deep-learning/project/ANeurIPS2024_SPV-MIA_not_official/ft_llms/llms_finetune.py\"\n",
        "\n",
        "# Verify the file exists\n",
        "print(f\"Script exists: {os.path.exists(finetune_script_path)}\")\n",
        "\n",
        "model_name = \"gpt2\"\n",
        "dataset_name = \"wikitext\"\n",
        "dataset_config_name = \"wikitext-2-raw-v1\"\n",
        "# Configure arguments as a dictionary\n",
        "\n",
        "target_args = {\n",
        "    \"output_dir\": \"./ft_llms/{model_name}/{dataset_name}/target/\",\n",
        "    \"block_size\": 128,\n",
        "    \"eval_steps\": 100,\n",
        "    \"save_epochs\": 100,\n",
        "    \"log_steps\": 100,\n",
        "    \"dataset_name\": dataset_name,\n",
        "    \"model_name\": model_name,\n",
        "    \"packing\": True,\n",
        "    \"use_dataset_cache\": True,\n",
        "    \"epochs\": 10,\n",
        "    \"batch_size\": 16,\n",
        "    \"learning_rate\": 1e-4,\n",
        "    \"gradient_accumulation_steps\": 1,\n",
        "    \"train_sta_idx\": 0,\n",
        "    \"train_end_idx\": 2000,\n",
        "    \"eval_sta_idx\": 0,\n",
        "    \"eval_end_idx\": 500,\n",
        "    \"dataset_config_name\": dataset_config_name,\n",
        "    \"disable_flash_attention\": True  # Added to avoid flash attention issues\n",
        "}\n",
        "\n",
        "# Import the function\n",
        "sys.path.append(os.path.dirname(finetune_script_path))\n",
        "from llms_finetune import main_llms_finetune\n",
        "\n",
        "# Run the fine-tuning with the dictionary arguments\n",
        "main_llms_finetune(target_args)\n",
        "\n",
        "# Launch fine-tuning test using gpt2 and small wikitext-2-raw-v1 slice\n",
        "# !accelerate launch ./ft_llms/llms_finetune.py \\\n",
        "# --output_dir ./ft_llms/gpt2/wikitext/target/ \\\n",
        "# --block_size 128 --eval_steps 100 --save_epochs 100 --log_steps 100 \\\n",
        "# -d wikitext -m gpt2 --packing --use_dataset_cache \\\n",
        "# -e 2 -b 2 -lr 1e-4 --gradient_accumulation_steps 1 \\\n",
        "# --train_sta_idx=0 --train_end_idx=2000 --eval_sta_idx=0 --eval_end_idx=500 \\\n",
        "# --dataset_config_name wikitext-2-raw-v1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0vcFz6ac9c-7",
      "metadata": {
        "id": "0vcFz6ac9c-7"
      },
      "source": [
        "# Self-prompt Reference Model Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nu04XTaI9gnm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nu04XTaI9gnm",
        "outputId": "c61ee4c4-c049-4670-cc25-2550957d1de0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Script exists: True\n",
            "Running with arguments: <src.parser.Args object at 0x7f6b30211450>\n",
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/liranc6/miniconda3/envs/spv_attack311/lib/python3.11/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model from: ./ft_llms/gpt2/wikitext/target/checkpoint-2000\n",
            "Pad token id is None, setting to eos token id...\n",
            "Preparing datasets...\n",
            "Folder './cache/wikitext/wikitext-2-raw-v1' already exists.\n",
            "Train dataset size: 16585\n",
            "Generating texts...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/6585 [00:00<?, ?it/s]/home/liranc6/miniconda3/envs/spv_attack311/lib/python3.11/site-packages/transformers/generation/utils.py:1421: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
            "  warnings.warn(\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "  0%|          | 1/6585 [00:04<8:03:14,  4.40s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample generated text:  lowest bid. \n",
            " The city of Las Vegas had lobbied hard to be the next city to legalize recreational m...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 2/6585 [00:06<5:04:02,  2.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "  0%|          | 3/6585 [00:07<3:57:14,  2.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "  0%|          | 4/6585 [00:08<3:25:13,  1.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "  0%|          | 5/6585 [00:10<3:07:26,  1.71s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "  0%|          | 6/6585 [00:11<2:56:49,  1.61s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "  0%|          | 6/6585 [00:12<3:56:04,  2.15s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrefer_data_generate\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run_data_generation\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Run the data generation with the dictionary arguments\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[43mrun_data_generation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrefer_data_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# !accelerate launch ./ft_llms/refer_data_generate.py \\\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# -tm ./ft_llms/gpt2/wikitext/target/checkpoint-2000 \\\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# -m gpt2 -d wikitext \\\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# --dataset_config_name wikitext-2-raw-v1\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/W25/adversarial-attacks-on-deep-learning/project/ANeurIPS2024_SPV-MIA_not_official/ft_llms/refer_data_generate.py:104\u001b[39m, in \u001b[36mrun_data_generation\u001b[39m\u001b[34m(args)\u001b[39m\n\u001b[32m     97\u001b[39m     gen_tokens = model.module.generate(\n\u001b[32m     98\u001b[39m         clipped_ids,\n\u001b[32m     99\u001b[39m         num_beams=\u001b[32m1\u001b[39m,\n\u001b[32m    100\u001b[39m         do_sample=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    101\u001b[39m         max_length=input_ids.size(-\u001b[32m1\u001b[39m),\n\u001b[32m    102\u001b[39m     )\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     gen_tokens = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclipped_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model_type == \u001b[33m\"\u001b[39m\u001b[33mllama\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    112\u001b[39m     gen_tokens = gen_tokens[:, \u001b[32m1\u001b[39m:]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/spv_attack311/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/spv_attack311/lib/python3.11/site-packages/transformers/generation/utils.py:1652\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[39m\n\u001b[32m   1644\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   1645\u001b[39m         input_ids=input_ids,\n\u001b[32m   1646\u001b[39m         expand_size=generation_config.num_return_sequences,\n\u001b[32m   1647\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   1648\u001b[39m         **model_kwargs,\n\u001b[32m   1649\u001b[39m     )\n\u001b[32m   1651\u001b[39m     \u001b[38;5;66;03m# 13. run sample\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1652\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1653\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1656\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1657\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1658\u001b[39m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1659\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1660\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1661\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1662\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1663\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1664\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1666\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode == GenerationMode.BEAM_SEARCH:\n\u001b[32m   1667\u001b[39m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[32m   1668\u001b[39m     beam_scorer = BeamSearchScorer(\n\u001b[32m   1669\u001b[39m         batch_size=batch_size,\n\u001b[32m   1670\u001b[39m         num_beams=generation_config.num_beams,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1675\u001b[39m         max_length=generation_config.max_length,\n\u001b[32m   1676\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/spv_attack311/lib/python3.11/site-packages/transformers/generation/utils.py:2734\u001b[39m, in \u001b[36mGenerationMixin.sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   2731\u001b[39m model_inputs = \u001b[38;5;28mself\u001b[39m.prepare_inputs_for_generation(input_ids, **model_kwargs)\n\u001b[32m   2733\u001b[39m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2734\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m   2735\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2736\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   2737\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2738\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2739\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2741\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[32m   2742\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/spv_attack311/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/spv_attack311/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/spv_attack311/lib/python3.11/site-packages/accelerate/utils/operations.py:636\u001b[39m, in \u001b[36mconvert_outputs_to_fp32.<locals>.forward\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    635\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(*args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m636\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/spv_attack311/lib/python3.11/site-packages/accelerate/utils/operations.py:624\u001b[39m, in \u001b[36mConvertOutputsToFp32.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    623\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m624\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/spv_attack311/lib/python3.11/site-packages/torch/amp/autocast_mode.py:44\u001b[39m, in \u001b[36mautocast_decorator.<locals>.decorate_autocast\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_autocast\u001b[39m(*args, **kwargs):\n\u001b[32m     43\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/spv_attack311/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:1076\u001b[39m, in \u001b[36mGPT2LMHeadModel.forward\u001b[39m\u001b[34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m   1068\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1069\u001b[39m \u001b[33;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[32m   1070\u001b[39m \u001b[33;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[32m   1071\u001b[39m \u001b[33;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[32m   1072\u001b[39m \u001b[33;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[32m   1073\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1074\u001b[39m return_dict = return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.use_return_dict\n\u001b[32m-> \u001b[39m\u001b[32m1076\u001b[39m transformer_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1077\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1078\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1079\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1080\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1081\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1082\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1083\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1084\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1085\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1086\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1087\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1088\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1089\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1090\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1091\u001b[39m hidden_states = transformer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1093\u001b[39m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/spv_attack311/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/spv_attack311/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/spv_attack311/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:900\u001b[39m, in \u001b[36mGPT2Model.forward\u001b[39m\u001b[34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    890\u001b[39m     outputs = torch.utils.checkpoint.checkpoint(\n\u001b[32m    891\u001b[39m         create_custom_forward(block),\n\u001b[32m    892\u001b[39m         hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    897\u001b[39m         encoder_attention_mask,\n\u001b[32m    898\u001b[39m     )\n\u001b[32m    899\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m900\u001b[39m     outputs = \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    901\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    902\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    903\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    904\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    905\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    906\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    907\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    908\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    909\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    911\u001b[39m hidden_states = outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    912\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/spv_attack311/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/spv_attack311/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/spv_attack311/lib/python3.11/site-packages/transformers/models/gpt2/modeling_gpt2.py:426\u001b[39m, in \u001b[36mGPT2Block.forward\u001b[39m\u001b[34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[39m\n\u001b[32m    423\u001b[39m     outputs = outputs + cross_attn_outputs[\u001b[32m2\u001b[39m:]  \u001b[38;5;66;03m# add cross attentions if we output attention weights\u001b[39;00m\n\u001b[32m    425\u001b[39m residual = hidden_states\n\u001b[32m--> \u001b[39m\u001b[32m426\u001b[39m hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mln_2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    427\u001b[39m feed_forward_hidden_states = \u001b[38;5;28mself\u001b[39m.mlp(hidden_states)\n\u001b[32m    428\u001b[39m \u001b[38;5;66;03m# residual connection\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/spv_attack311/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/spv_attack311/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/spv_attack311/lib/python3.11/site-packages/torch/nn/modules/normalization.py:217\u001b[39m, in \u001b[36mLayerNorm.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43meps\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/spv_attack311/lib/python3.11/site-packages/torch/nn/functional.py:2900\u001b[39m, in \u001b[36mlayer_norm\u001b[39m\u001b[34m(input, normalized_shape, weight, bias, eps)\u001b[39m\n\u001b[32m   2890\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[32m   2891\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m   2892\u001b[39m         layer_norm,\n\u001b[32m   2893\u001b[39m         (\u001b[38;5;28minput\u001b[39m, weight, bias),\n\u001b[32m   (...)\u001b[39m\u001b[32m   2898\u001b[39m         eps=eps,\n\u001b[32m   2899\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m2900\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2901\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackends\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcudnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43menabled\u001b[49m\n\u001b[32m   2902\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# Get the path to refer_data_generate.py\n",
        "refer_data_script_path = \"/home/liranc6/W25/adversarial-attacks-on-deep-learning/project/ANeurIPS2024_SPV-MIA_not_official/ft_llms/refer_data_generate.py\"\n",
        "\n",
        "# Verify the file exists\n",
        "print(f\"Script exists: {os.path.exists(refer_data_script_path)}\")\n",
        "\n",
        "# Configure arguments as a dictionary\n",
        "refer_data_args = {\n",
        "    \"model_name\": model_name,\n",
        "    \"target_model\": \"./ft_llms/{model_name}/{dataset_name}/target\",\n",
        "    \"dataset_name\": dataset_name,\n",
        "    \"dataset_config_name\": dataset_config_name,\n",
        "    \"cache_path\": \"./cache\",\n",
        "    \"use_dataset_cache\": True,\n",
        "    \"packing\": True,\n",
        "    \"block_size\": 128,\n",
        "    \"preprocessing_num_workers\": 1,\n",
        "    \"validation_split_percentage\": 0.1,\n",
        "    \"local_files_only\": False\n",
        "}\n",
        "\n",
        "# Import the function\n",
        "sys.path.append(os.path.dirname(refer_data_script_path))\n",
        "from refer_data_generate import run_data_generation\n",
        "\n",
        "# Run the data generation with the dictionary arguments\n",
        "run_data_generation(refer_data_args)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# !accelerate launch ./ft_llms/refer_data_generate.py \\\n",
        "# -tm ./ft_llms/gpt2/wikitext/target/checkpoint-2000 \\\n",
        "# -m gpt2 -d wikitext \\\n",
        "# --dataset_config_name wikitext-2-raw-v1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e888687",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 10604\n",
            "drwxr-xr-x 5 liranc6 domain^users    4096 May 13 19:31 .\n",
            "drwxr-xr-x 3 liranc6 domain^users    4096 May 13 17:21 ..\n",
            "drwxr-xr-x 3 liranc6 domain^users    4096 May 13 18:42 attack_data_gpt2@wikitext\n",
            "drwxr-xr-x 3 liranc6 domain^users    4096 May 13 18:13 refer@gpt2\n",
            "drwxr-xr-x 3 liranc6 domain^users    4096 May 13 19:31 refer@tiiuae\n",
            "-rw-r--r-- 1 liranc6 domain^users 9690328 May 13 17:21 train_dataset\n",
            "-rw-r--r-- 1 liranc6 domain^users 1093224 May 13 17:22 valid_dataset\n"
          ]
        }
      ],
      "source": [
        "# Check if the reference data directory exists\n",
        "# !ls -la ./cache/wikitext/wikitext-2-raw-v1/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb2a2c70",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Script exists: True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/liranc6/miniconda3/envs/spv_attack311/lib/python3.11/site-packages/peft/tuners/lora/model.py:311: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 2359296 || all params: 126799104 || trainable%: 1.8606566809809635\n",
            "Folder './cache/wikitext/wikitext-2-raw-v1' already exists.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using pad_token, but it is not set yet.\n",
            "/home/liranc6/miniconda3/envs/spv_attack311/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:166: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
            "  warnings.warn(\n",
            "Map: 100%|██████████| 32/32 [00:00<00:00, 1846.97 examples/s]\n",
            "Map: 100%|██████████| 500/500 [00:00<00:00, 8169.69 examples/s]\n",
            "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [32/32 00:02, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# Get the path to llms_finetune.py\n",
        "finetune_script_path = \"/home/liranc6/W25/adversarial-attacks-on-deep-learning/project/ANeurIPS2024_SPV-MIA_not_official/ft_llms/llms_finetune.py\"\n",
        "\n",
        "# Verify the file exists\n",
        "print(f\"Script exists: {os.path.exists(finetune_script_path)}\")\n",
        "\n",
        "# Configure reference model arguments as a dictionary\n",
        "reference_args = {\n",
        "    \"refer\": True,\n",
        "    \"output_dir\": f\"./ft_llms/{model_name}/{dataset_name}/refer/\",\n",
        "    \"block_size\": 128,\n",
        "    \"eval_steps\": 100,\n",
        "    \"save_epochs\": 100,\n",
        "    \"log_steps\": 100,\n",
        "    \"dataset_name\": dataset_name,\n",
        "    \"model_name\": model_name,\n",
        "    \"packing\": True,\n",
        "    \"use_dataset_cache\": True,\n",
        "    \"epochs\": 2,\n",
        "    \"batch_size\": 2,\n",
        "    \"learning_rate\": 5e-5,\n",
        "    \"gradient_accumulation_steps\": 1,\n",
        "    \"train_sta_idx\": 0,\n",
        "    \"train_end_idx\": 2000,\n",
        "    \"eval_sta_idx\": 0,\n",
        "    \"eval_end_idx\": 500,\n",
        "    \"dataset_config_name\": dataset_config_name,\n",
        "    \"disable_flash_attention\": True  # Added to avoid flash attention issues\n",
        "}\n",
        "\n",
        "# Import the function if not already imported\n",
        "if 'main_llms_finetune' not in globals():\n",
        "    sys.path.append(os.path.dirname(finetune_script_path))\n",
        "    from llms_finetune import main_llms_finetune\n",
        "\n",
        "# Run reference model fine-tuning\n",
        "main_llms_finetune(reference_args)\n",
        "\n",
        "# !accelerate launch ./ft_llms/llms_finetune.py --refer \\\n",
        "# --output_dir ./ft_llms/gpt2/wikitext/refer/ \\\n",
        "# --block_size 128 --eval_steps 100 --save_epochs 100 --log_steps 100 \\\n",
        "# -d wikitext -m gpt2 --packing --use_dataset_cache \\\n",
        "# -e 2 -b 2 -lr 5e-5 --gradient_accumulation_steps 1 \\\n",
        "# --train_sta_idx=0 --train_end_idx=2000 --eval_sta_idx=0 --eval_end_idx=500 \\\n",
        "# --dataset_config_name wikitext-2-raw-v1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pT9KrvIT-ZhF",
      "metadata": {
        "id": "pT9KrvIT-ZhF"
      },
      "source": [
        "# Run SPV-MIA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48e4b40a",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "[nltk_data] Downloading package wordnet to /home/liranc6/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /home/liranc6/nltk_data...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment ready for attack script\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Add this to a cell in your notebook:\n",
        "# import os\n",
        "# os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"  # Avoid huggingface tokenizer warnings\n",
        "\n",
        "# Install a compatible version of NLTK for Python 3.11\n",
        "# !pip install -q nltk==3.8.1\n",
        "\n",
        "# Download necessary NLTK data\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "print(\"Environment ready for attack script\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zG96TTKK-ibT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zG96TTKK-ibT",
        "outputId": "a2b14dfc-3022-4f37-940f-5eb8c1fc66c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Script exists: True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/liranc6/miniconda3/envs/spv_attack311/lib/python3.11/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/home/liranc6/miniconda3/envs/spv_attack311/lib/python3.11/site-packages/transformers/modeling_utils.py:484: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=map_location)\n",
            "05/15/2025 15:27:31 - INFO - run_attack - Successfully load models\n",
            "05/15/2025 15:27:32 - INFO - run_attack - Pad token id is None, setting to eos token id...\n",
            "05/15/2025 15:27:38 - INFO - run_attack - Successfully load datasets!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Folder './cache/wikitext/wikitext-2-raw-v1' already exists.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "05/15/2025 15:27:45 - INFO - attack.attack_model - Preparing data...\n",
            "05/15/2025 15:27:45 - INFO - attack.attack_model - Generating feature vectors for member data...\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]/home/liranc6/miniconda3/envs/spv_attack311/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING: 1 texts have no fills. Trying again [attempt 1].\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [04:37<00:00, 277.65s/it]\n",
            "05/15/2025 15:32:23 - INFO - attack.attack_model - Generating feature vectors for non-member data...\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# Get the path to attack.py\n",
        "attack_script_path = \"/home/liranc6/W25/adversarial-attacks-on-deep-learning/project/ANeurIPS2024_SPV-MIA_not_official/run_attack.py\"\n",
        "\n",
        "# Verify the file exists\n",
        "print(f\"Script exists: {os.path.exists(attack_script_path)}\")\n",
        "\n",
        "# Import the attack function\n",
        "sys.path.append(os.path.dirname(attack_script_path))\n",
        "from run_attack import run_attack  # Adjust if the function has a different name\n",
        "\n",
        "model_name = \"gpt2\"\n",
        "dataset_name = \"wikitext\"\n",
        "dataset_config_name = \"wikitext-2-raw-v1\"\n",
        "\n",
        "attack_args = {\n",
        "    \"model_name\": model_name,\n",
        "    \"dataset_name\": dataset_name,\n",
        "    \"dataset_config_name\": dataset_config_name,\n",
        "    \"target_model\": f\"./ft_llms/{model_name}/{dataset_name}/target/\",\n",
        "    \"reference_model\": f\"./ft_llms/{model_name}/{dataset_name}/refer/\",\n",
        "    }\n",
        "\n",
        "# Run the attack with dictionary arguments\n",
        "run_attack(attack_args)\n",
        "\n",
        "# # Import directly from the module file \n",
        "# from attack import run_attack as run_attack_func  # Rename to avoid potential conflicts\n",
        "\n",
        "# run_attack_func()\n",
        "\n",
        "# !python attack.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ZwGsi1ORdKk8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        },
        "id": "ZwGsi1ORdKk8",
        "outputId": "971fa3c7-2170-47a7-ec80-e28427238a74"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load ROC curve data\n",
        "data = np.load(\"./cache/wikitext/wikitext-2-raw-v1/attack_data_gpt2@wikitext/roc_stat.npz\")\n",
        "fpr = data[\"fpr\"]\n",
        "tpr = data[\"tpr\"]\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, label=f'ROC curve (AUC = {np.round(np.trapz(tpr, fpr), 4)})')\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label=\"Random guess\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve – Statistical Membership Inference Attack\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Mark TPR@1%FPR\n",
        "fpr_1_index = np.argmin(np.abs(fpr - 0.01))\n",
        "plt.scatter(fpr[fpr_1_index], tpr[fpr_1_index], color='red', label=f'TPR@1%FPR: {tpr[fpr_1_index]:.3f}')\n",
        "plt.legend()\n",
        "\n",
        "# Save the figure\n",
        "plt.savefig(\"roc_stat.png\", dpi=300)\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "spv_attack311",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
